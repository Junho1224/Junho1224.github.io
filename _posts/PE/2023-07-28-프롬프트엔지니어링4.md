---
layout: post
title: "What is Prompt Engineering?"
subtitle: "이건어디에들어가는거지"
category: PE
tags: 프롬프트엔지니어 PE
comments: true
---

# About Prompt Engineering : 4.프롬프트 예시

이전 섹션에서는 LLM을 확인하는 방법에 대한 기본적인 예를 소개했습니다.

이번 섹션에서는 프롬프트를 사용하여 다양한 작업을 수행하고 그 과정에서 주요 개념을 소개하는 방법에 대한 더 많은 예를 제공합니다. 아래의 몇 가지 예는 잘 만들어진 프롬프트를 사용하여 다양한 유형의 작업을 수행하는 방법을 보여줍니다.

### 텍스트 요약 (Text Summarization)

자연어 생성의 표준 작업 중 하나는 텍스트 요약입니다. 말 그대로 긴 문서나 글을 짧게 요약하는 작업을 말합니다. 사실, 언어 모델의 가장 유망한 응용 프로그램 중 하나는 기사와 개념을 빠르고 읽기 쉬운 요약으로 요약할 수 있는 능력입니다. 프롬프트를 사용하여 기본 요약 작업을 시도해 보겠습니다.

정릉에 대해 알고 싶다고 가정해 보겠습니다. 다음과 같은 프롬프트를 시도할 수 있습니다.

*프롬프트:*

```
정릉에 대해 설명해줘
답변:
```

*출력:*

```
정릉(正陵)은 대한민국 서울에 위치한 조선시대 왕들의 묘역으로, 조선 왕조의 제9대인 세종대왕부터 현종대왕까지 17명의 왕들과 왕비들, 명나라의 임금 단헌왕비 등이 묘역으로 안치되어 있습니다. 이곳은 한국의 역사와 문화를 반영하는 귀중한 유적지 중 하나로 꼽히며, 많은 관광객과 역사 애호가들이 방문하는 곳입니다.

정릉은 조선 왕조의 묘역으로, 왕의 묘와 그 왕비들의 묘가 함께 있습니다. 조선 왕은 죽은 후 태자의 위치에서 순서대로 묘를 지어주었는데, 이를 성혼이라고 합니다. 성혼은 궁궐과 비슷한 형태로 건축되었으며, 고려 시대의 왕릉 양식을 따라 만들어졌습니다. 성혼은 물과 산에 좋은 위치에 지어졌으며, 물이 언제나 흐르고 향기롭고 아름다운 경치를 자랑합니다.(생략)
```

프롬프트에 들어간 "답변:" 는 질문 답변에 사용하는 명시적인 프롬프트 형식입니다. 여기서 이 정보를 사용하여 모델에게 추가로 예상되는 답이 있음을 알렸습니다. 이 예에서는 사용하지 않는 것과 사용하지 않는 것이 어떤 차이가 있는지 명확하지 않지만, 나중에 나올 예시에서는 큰 차이를 느낄 수 있습니다. 

gpt의 답변이 너무 많은 정보라고 가정하고 더 요약하려고 합니다. 실제로 모델에게 다음과 같이 한 문장으로 요약하도록 지시할 수 있습니다.

*프롬프트:*

```
정릉(正陵)은 대한민국 서울에 위치한 조선시대 왕들의 묘역으로, 조선 왕조의 제9대인 세종대왕부터 현종대왕까지 17명의 왕들과 왕비들, 명나라의 임금 단헌왕비 등이 묘역으로 안치되어 있습니다. 이곳은 한국의 역사와 문화를 반영하는 귀중한 유적지 중 하나로 꼽히며, 많은 관광객과 역사 애호가들이 방문하는 곳입니다.

정릉은 조선 왕조의 묘역으로, 왕의 묘와 그 왕비들의 묘가 함께 있습니다. 조선 왕은 죽은 후 태자의 위치에서 순서대로 묘를 지어주었는데, 이를 성혼이라고 합니다. 성혼은 궁궐과 비슷한 형태로 건축되었으며, 고려 시대의 왕릉 양식을 따라 만들어졌습니다. 성혼은 물과 산에 좋은 위치에 지어졌으며, 물이 언제나 흐르고 향기롭고 아름다운 경치를 자랑합니다.

위 내용을 한 문장으로 설명해줘:
```

*출력:*

```
정릉은 대한민국 서울에 위치한 조선시대 왕들의 묘역으로, 세종대왕부터 현종대왕까지 17명의 왕들과 왕비들, 명나라의 임금 단헌왕비 등이 묘역으로 안치된 한국의 역사와 문화를 반영하는 중요한 유적지로 많은 관광객과 역사 애호가들이 방문하는 곳입니다.
```

chat gpt에서는 유저와 주고받은 대화 내용을 기억하기 때문에 문서 없이 ‘한 문장으로 설명해줘’ 라고 지시해도 잘 수행 합니다. 또한 gpt로부터 응답받은 문서가 아닌, 외부의 데이터를 가지고와 input data로 넣고 요청을 해도 요약문을 잘 생성해 줄 것입니다.

프롬프에 그냥 요약을 해달라고 요청하는 것보다 내가 보고싶은 관점에 대해서 요약을 해달라고 하면, 다른 요약문이 생성됩니다. 즉, 어떻게 요약해달라고 요청하느냐에 따라 원하는 정보를 추출할 수 있습니다.

앞서서는 단락을 한 문장으로 요약하라고 했습니다. 모델은 지침에 맞게 알맞은 결과를 출력했지만, 여기서 잠시 멈추고 더 나은 결과가 나오는지 실험해 보세요

출력의 정확성에 대해서는 이후에 다룰 예정입니다.

---

### 정보 추출 (Information Extraction)

언어 모델은 자연어 생성 및 관련 작업을 수행하도록 훈련되었지만 분류 및 다양한 자연어 처리(NLP) 작업을 수행할 수도 있습니다.

다음은 주어진 단락에서 정보를 추출하는 프롬프트의 예입니다.

*프롬프트:*

```
이강인은 PSG행 급물살을 탔다. 유럽 축구 이적시장에 정통한 파브리시오 로마노는 "PSG와 이강인이 장기 계약에 대한 구두 합의에 도달했다. 메디컬 테스트도 이미 마무리됐다. 마지막 세부 사항 조율만 남았다. 이강인 PSG행 관련 모든 당사자들은 계약 성사에 자신감을 갖고 있으며 두 클럽 사이 구두 합의도 이루어졌다. 서명만 기다리는 중이다"라며 계약 성사를 뜻하는 시그니처 'here we go'를 남겼다.

프랑스 현지에선 루이스 엔리케 감독 선임 발표 이후 영입생 오피셜이 나올 거라 예상했다. 엔리케 감독은 2014-15시즌 당시 바르셀로나와 함께 스페인 라리가, 코파 델 레이, 유럽축구연맹(UEFA) 챔피언스리그(UCL) 우승으로 '트레블'을 달성했다.

엔리케 감독 선임이 확정되자 '오피셜 러시'가 이어졌다. 밀란 슈크리니아르, 마르코 아센시오, 마누엘 우가르테가 차례로 발표되면서 기대감이 점점 고조됐다. 다음 주인공은 바로 이강인이었다. 8일 오전 인천국제공항을 통해 파리로 떠난 다음 프랑스에 도착한지 얼마 지나지 않아 공식 발표가 나왔다. 발렌시아에서 방출됐던 선수가 '빅이어(UCL 우승 트로피)'를 노리는 PSG에 바이아웃으로 영입된 것이다.

위 단락에서 PSG의 감독을 언급해주세요:
```

*출력:*

```
위 단락에서 PSG의 감독은 루이스 엔리케입니다.
```

위의 결과를 개선할 수 있는 방법은 여러 가지가 있지만 이미 매우 유용합니다.

이제 모델에게 무엇을 해야 하는지 지시하는 것 만으로 다양한 작업을 수행하도록 요청할 수 있습니다. 

문단 출처 : [네이버 스포츠](https://sports.news.naver.com/news?oid=413&aid=0000163318)

---

### 질문 답변 (Question Answering)

모델이 특정 답변에 응답하도록 하는 가장 좋은 방법 중 하나는 프롬프트 형식을 개선하는 것입니다. 앞에서 설명한 것처럼 프롬프트는 지침, 컨텍스트, 입력 및 출력 표시기를 결합하여 향상된 결과를 얻을 수 있습니다. 이러한 구성 요소가 꼭 필요하지는 않지만 지침을 구체화 할수록 더 좋은 결과를 얻을 수 있기 때문에 좋은 방법이 됩니다. 다음은 좀 더 체계적인 프롬프트를 실행 했을 때의 모습을 보여주는 예입니다.

*프롬프트:*

```
Answer the question based on the context below. Keep the answer short and concise. Respond "Unsure about answer" if not sure about the answer.
Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.
Question: What was OKT3 originally sourced from?
Answer:
```

*출력:*

```
Mice.
```


갑분영어

---

### 텍스트 분류 (Text Classification)

지금까지 간단한 지침을 사용하여 작업을 수행했는데요, 우리는 프롬프트 엔지니어로서 더 나은 지침을 제공하는 것을 더 잘 할 필요가 있습니다. 또한 더 어려운 사용 사례의 경우 지침만 제공해도 충분하지 않다는 것을 알게 될 것입니다. 그 때는 상황과 프롬프트에서 사용할 수 있는 다양한 요소에 대해 더 많이 생각해야 합니다. `input data`또는`examples`을 제공해서 시연해보겠습니다.

![Untitled](/assets/img/About%20Prompt%20Engineering/Untitled%208.png)

당신은 텍스트를 분류하라는 지침을 내렸고 모델은 다음과 같이 응답했습니다. 생각했던 답이 `'중립'` 이 맞나요? `'중립'` 또한 충분히 맞는 답입니다. 하지만 당신이 `'긍정'` 의 감정이 나타나길 원했다면 어떻게 이를 달성할 수 있을까요? 이렇게 하는 데는 여러 가지 방법이 있습니다. 여기서는 특수성에 관심이 있으므로 프롬프트에 더 많은 정보를 제공할수록 더 좋은 결과를 얻을 수 있습니다. 예제를 제공하여 올바른 동작을 지정할 수 있습니다. 다시 시도해 보겠습니다.

![Untitled](/assets/img/About%20Prompt%20Engineering/Untitled%209.png)

같은 질문이었지만 답변이 달라졌습니다. 프롬프트에 제공된 예제는 모델의 출력을 구체화하는 데 도움이 된 것으로 보입니다.

사실 모델은 `'중립'` 의 레이블에 있어서 약간의 편견을 가지고 있습니다.

‘강한긍정’ 이나 ‘부정’이 없으면 거의 중립으로 분류되는 것을 테스트 해보시면 알 수 있습니다. 

이런 넓은 범위의 중립을 더확실한 `'중립'` 의 레이블로 만들기 위해서 어떻게 수정하실 건가요? 라벨에 설명을 추가하거나 프롬프트에 예제를 더 추가할 수 있나요?

다음 섹션에서는 이것에 관련해서 몇가지 이야기를 할 예정입니다

---

### 대화 (Conversation)

프롬프트 엔지니어링을 통해 달성할 수 있는 더 흥미로운 것 중 하나는 LLM 시스템에 동작 방법, 의도 및 정체성을 지시하는 것입니다. 이것은 고객 서비스 챗봇과 같은 대화형 시스템을 구축할 때 특히 유용합니다.

예를 들어, 질문에 대한 보다 기술적이고 과학적인 답변을 생성할 수 있는 대화 시스템을 만들어 보겠습니다. 지침을 통해 어떻게 행동해야 하는지 명시적으로 알려주는 방법에 주목합니다. 이를 role prompting이라고도 합니다.

*프롬프트:*

```
다음은 우주연구원의 조수와의 대화입니다. 조수는 기술적이고 과학적입니다.
인간: 안녕하세요
AI: 안녕하세요! 저는 우주연구원의 조수입니다. 오늘 제가 어떻게 도와드릴까요?
인간: 블랙홀은 어떻게 생기는지 알려줄래요?
AI:
```

*출력:*

```
물론이죠! 블랙홀은 매우 특이한 천체입니다. 블랙홀은 무거운 별들이 그 특이한 질량과 중력으로 인해 끝나는 현상입니다. 별은 자신의 연소 에너지를 소모하면서 핵융합 반응을 일으킵니다. 이 반응이 지속되다가 연료가 다 소진되면, 별은 외부로 빛을 내뿜는 초신성 폭발을 일으키게 됩니다.

초신성 폭발 이후에는 남은 핵물질이 중력에 의해 별의 중심으로 무진장 무거운 질량을 압축시킵니다. 이런 과정을 "중력 붕괴"라고 합니다. 중력 붕괴가 충분히 강하면 별의 중심 부근에서 중력이 너무 강력하여 빛마저 튀어나올 수 없는 상태가 됩니다. 이렇게 빛도 빠져나올 수 없는 지역을 "이벤트 호라이즌"이라고 합니다.

이벤트 호라이즌 안에 있는 영역은 블랙홀의 질량과 크기에 따라 다양한 특성을 가지게 됩니다. 이 영역 안에서는 중력이 엄청나게 강력해져서 시공간 자체가 왜곡되고, 그 영향을 벗어날 수 없습니다. 따라서 이벤트 호라이즌을 넘어서면 블랙홀의 영향에서 벗어날 수 없다는 것이고, 이로 인해 블랙홀은 매우 특이한 우주 현상으로 알려져 있습니다.
```

연구원 조수의 대답이 좀 기술적으로 들리죠? 이해하기 쉬운 답변을 받을 수 있도록 지시문을 바꿔보겠습니다.

*프롬프트:*

```
다음은 우주연구원의 조수와의 대화입니다. 조수의 답안은 초등학생도 쉽게 이해할 수 있어야 합니다. 
인간: 안녕하세요
AI: 안녕하세요! 저는 우주연구원의 조수입니다. 오늘 제가 어떻게 도와줄까요?
인간: 블랙홀은 어떻게 생기는지 알려줄래요?
AI:
```

*출력:*

```
물론이죠! 블랙홀에 대해 간단히 설명드리겠습니다. 블랙홀은 매우 무거운 별이 끝나고 무너지면서 생기는 물체입니다. 별은 자기 자신의 중력으로 인해 계속해서 수축하다가 질량이 너무 많아지면 블랙홀이 됩니다.

블랙홀은 놀라울 정도로 강한 중력을 가지고 있어서 주변에 있는 모든 물질을 흡수할 수 있습니다. 빛도 블랙홀 주변에서는 흡수되기 때문에 우리는 블랙홀을 직접 관측하기 어렵습니다.

블랙홀은 우주에 있는 여러 현상들을 이해하는데 중요한 역할을 합니다. 하지만 우리에게는 아직 많은 미스터리가 남아있는 분야이기도 합니다. 우주에 대한 더 많은 연구와 관찰을 통해서 블랙홀에 대해 더 많은 것을 알아가고 있습니다.
```

진전이 좀 있었습니다. 이런 식으로 예제를 더 추가하면 훨씬 더 좋은 결과를 얻을 수 있습니다.

---

### 코드 생성 (Code Generation)

생성형 ai의 꽃이라고 볼 수 있는 코드 생성입니다. Copilot과 [Code Interpreter](https://junho1224.github.io/pe/2023-07-25-%EC%BD%94%EB%93%9C%EC%9D%B8%ED%84%B0%ED%94%84%EB%A6%AC%ED%84%B0/)가 아주 좋은 예시이죠, 프롬프트를 통해 수행할 수 있는 코드 생성은 매우 방대합니다.

먼저 사용자에게 인사하는 간단한 프로그램을 시도해 보겠습니다.

*프롬프트:*

```
/*
사용자에게 이름을 묻고 "안녕하세요"라고 말합니다
*/
```

*출력:*

```
<!DOCTYPE html>
<html>
<head>
    <title>인사하는 프로그램</title>
</head>
<body>
    <script>
        // 사용자에게 이름을 묻기 위한 prompt() 함수를 사용합니다.
        var name = prompt("이름을 입력하세요:");

        // 사용자의 이름을 확인하여 인사 메시지를 만듭니다.
        var greeting = "안녕하세요, " + name + "님!";
        alert(greeting); // 인사 메시지를 경고창으로 출력합니다.
    </script>
</body>
</html>
```

사용할 언어를 지정할 필요도 없었습니다.

더 놀라운점은 코드를 생성해달라고 요청하지 않았는데, 주석안에 있음을 확인하고 코드를 생성해주었습니다. 

레벨을 조금 바꿔보겠습니다. 아래의 예는 프롬프트를 설계하는 데 조금 더 많은 노력을 기울이면 LLM이 얼마나 강력해질 수 있는지 보여줍니다.

*프롬프트:*

```
Table departments, columns = [DepartmentId, DepartmentName]
Table students, columns = [DepartmentId, StudentId, StudentName]
Computer Science Department에서 모든 학생들을 조회하는 mysql 쿼리를 작성해주세요
```

*출력:*

```
SELECT s.StudentId, s.StudentName
FROM students s
JOIN departments d ON s.DepartmentId = d.DepartmentId
WHERE d.DepartmentName = 'Computer Science';
```
위의 경우 데이터베이스 스키마에 대한 데이터를 제공하고 유효한 MySQL 쿼리를 생성하도록 요청했습니다.

아주 기초적인 코드 생성이었지만 문제없이 코드를 출력해냈습니다.
더 복잡한 코드라도 프롬프트를 잘 설계한다면 수준급의 코드를 얻으실 수 있습니다.

---

### Reasoning

오늘날 LLM에게 가장 어려운 작업 중 하나는 어떤 형태로든 추론이 필요한 작업입니다. 추론은 LLM에서 나타날 수 있는 복잡한 응용 프로그램의 유형으로 인해 가장 흥미로운 분야 중 하나입니다.

수학적 능력을 포함하는 작업에서 몇 가지 개선이 있었지만, 현재 LLM은 추론 작업을 수행하는 데 어려움을 겪기 때문에 이를 위해서는 훨씬 더 ‘진보’된 프롬프트 엔지니어링 기술이 필요합니다. 그러한 고급 기술들은 다음 장에서 다룰 예정입니다.

![Untitled](/assets/img/About%20Prompt%20Engineering/Untitled%2010.png)

![Untitled](/assets/img/About%20Prompt%20Engineering/Untitled%2011.png)

보시는 것처럼, 더 나은 지침과 예는 더 정확한 결과로 이어질 수 있습니다.  

향후 가이드에서는 더 복잡한 프롬프트 엔지니어링 원칙에 대해 이야기 해보겠습니다.

---

## reference

- [https://mpost.io/prompt-engineering-ultimate-guide/](https://mpost.io/prompt-engineering-ultimate-guide/)
- [https://www.promptingguide.ai/](https://www.promptingguide.ai/)


<!-- 

![Untitled](/assets/img/About%20Prompt%20Engineering/Untitled%2010.png)

![Untitled](/assets/img/About%20Prompt%20Engineering/Untitled%2011.png)

# 방식

### 제로샷 프롬프트

지난번 짧게 여러 프롬프트의 방식에 대해 다뤘던걸 기억 하시나요? 이번에는 조금 더 깊게 다뤄보려고 합니다.

GPT-3와 같은 오늘날 대규모 LLM은 지침을 따르도록 조정되고 대량의 데이터에 대해 교육을 받기 때문에 일부 작업을 "제로샷"으로 수행할 수 있습니다.

이전 섹션에서 몇 가지 제로샷 예제를 시도했습니다.다음은 우리가 사용한 예 중 하나입니다.

*프롬프트:*

```
Classify the text into neutral, negative or positive. 
Text: I think the vacation is okay.
Sentiment:
```

*출력:*

```
Neutral
```

"Sentiment:"는 질문 답변에 사용하는 명시적인 프롬프트 형식입니다. 여기서 이 정보를 사용하여 모델에게 추가로 예상되는 답이 있음을 알릴 수 있습니다. 직접 테스트 해보시면서 있을 때와 없을 때의 차이를 확인해보세요!

위의 프롬프트에서 우리는 모델에 분류와 함께 텍스트의 예를 제공하지 않았습니다. LLM은 이미 "감정"을 이해하고 있습니다. 이것이 바로 제로샷 기능입니다.

명령 튜닝은 제로샷 [학습 Wei et](https://papago.naver.net/apis/site/proxy?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2109.01652.pdf) al. ([2022)](https://papago.naver.net/apis/site/proxy?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2109.01652.pdf)을 향상시키는 것으로 나타났습니다([새](https://papago.naver.net/apis/site/proxy?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2109.01652.pdf)탭에서 [열립니다](https://papago.naver.net/apis/site/proxy?url=https%3A%2F%2Farxiv.org%2Fpdf%2F2109.01652.pdf)).명령 튜닝은 기본적으로 명령을 통해 설명된 데이터 세트의 미세 조정 모델의 개념입니다.[또한](https://papago.naver.net/apis/site/proxy?url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03741), RLHF[(새 탭](https://papago.naver.net/apis/site/proxy?url=https%3A%2F%2Farxiv.org%2Fabs%2F1706.03741)에서 열기)(인간 피드백에서 학습 강화)는 모델이 인간의 선호도에 더 잘 맞도록 조정되는 확장 명령 튜닝에 채택되었습니다.이 최근의 개발은 ChatGPT와 같은 모델에 힘을 실어줍니다.다음 섹션에서는 이러한 모든 접근 방식과 방법에 대해 설명합니다.

제로샷이 작동하지 않을 때는 퓨샷 프롬프트로 이어지는 프롬프트에 데모 또는 예제를 제공하는 것이 좋습니다.다음 섹션에서는 퓨샷 프롬프트를 시연합니다.

### 원샷 프롬프트

원샷 프롬프트는 단일 예제 또는 템플릿과 같은 제한된 양의 입력 데이터로 자연어 텍스트를 생성하는 데 사용됩니다.

원샷 프롬프트를 대화 관리 및 컨텍스트 모델링과 같은 다른 자연어 처리 기술과 결합하여 보다 정교하고 효과적인 텍스트 생성 시스템을 만들 수 있습니다.

신속한 엔지니어링의 맥락에서 원샷 학습을 사용하여 단일 예제 또는 템플릿과 같은 제한된 양의 입력 데이터로 자연어 텍스트를 생성할 수 있습니다.

이를 통해 큰 언어 모델에서 예측 가능한 출력을 생성할 수 있습니다.

### 퓨샷 프롬프트

퓨샷 프롬프트는 이전에 본 객체의 새로운 예에 신속하게 적응하기 위해 모델에 일반적으로 2~5개의 예제가 제공되는 기술입니다.

퓨샷 학습은 제한된 양의 입력 데이터로 자연어 텍스트를 만들기 위해 신속한 엔지니어링의 맥락에서 사용될 수 있습니다. 필요한 데이터는 적지만 이 기술을 사용하면 보다 다양하고 적응형 텍스트 생성 모델을 만들 수 있습니다.

퓨샷 프롬프트와 같은 고급 기술을 사용하여 인간 사용자에게 더 유연하고 적응 가능하며 매력적인 자연어 생성 모델을 만들 수 있습니다.

### 제로 샷, 원 샷, 퓨 샷 프롬프트의 차이점

제로샷, 원샷 및 퓨샷 프롬프트는 GPT-3, GPT-4 또는 ChatGPT와 같은 대규모 언어 모델에서 더 나은 결과를 얻거나 더 빠른 결과를 얻는 데 사용할 수 있는 기술입니다.

제로샷 프롬프트는 모델이 추가 교육 없이 예측을 하는 반면, 원샷 프롬프트는 단일 예제 또는 템플릿을 포함하고 퓨샷 프롬프트는 다음과 같이 사용합니다일반적으로 두 개에서 다섯 개 사이의 소량의 데이터.

### 생각의 사슬 프롬프트

작년 구글에서 'Chain-of-Thought Prompting Elicits Reasoning in Large Language Models'라는 논문을 게재했는데, 이것이 언어모델의 성능을 크게 향상했다고 합니다. [(논문 링크)](https://arxiv.org/pdf/2201.11903.pdf)

바로 Chain-of-Thought(CoT)인데요.

### 생각의 나무 프롬프트

**생각의 나무(Tree-of-Thought)** 프롬프트는 생각의 나무 프레임워크에서 아이디어를 차용한 신선한 기술로 잘 확립된 생각의 사슬 프롬프트 개념을 확장하고 향상시켜 ChatGPT와 같은 큰 언어 모델이 우수한 추론 능력을 발휘할 수 있도록 합니다. 이 Tree-of-Thought Prompting 기술을 통해 Large Language Model은 점진적으로 지식을 축적하면서 오류를 자율적으로 수정할 수 있습니다.

ToT 프롬프트는 이전에는 대답할수 없던 질문에 대답할 수 있도록 ChatGPT 3.5의 추론 능력을 향상시킵니다.

### LLMs에 대한 복잡한 질문

LLM(대규모 언어 모델)은 종종 특정 유형의 복잡한 질문에 정확한 답을 못하는 경우기 있습니다 대표적인 예는 다음과 같습니다.

(참고한 눈문을 번역했습니다.)

```
밥은 거실에 있습니다.
그는 컵을 들고 부엌으로 걸어갑니다.
그는 컵에 공을 넣고 컵을 침실로 옮깁니다.
그는 컵을 뒤집고 정원으로 걸어갑니다.
그는 컵을 정원에 내려놓고 차고로 걸어갑니다.
공은 어디에 있나요?
```

정답은 ‘공은 침실에 있다’ 입니다.
gpt은 비결정론적이지만, 여러 번 시도하는 동안 받은 답변은 아래와 같습니다.

![아쉬운 모습을 보여주는 gpt 3.5](/assets/img/About%20Prompt%20Engineering/Untitled%2012.png)

아쉬운 모습을 보여주는 gpt 3.5

![정답을 맞춘 GPT 4](/assets/img/About%20Prompt%20Engineering/Untitled%2013.png)

정답을 맞춘 GPT 4

### **Chain-of-Thought prompting**

앞서 다뤘던 "생각의 사슬 프롬프트"(CoT)로 널리 알려진 개념이 존재하며, 이는 LLM(Large Language Model)이 생각 과정을 설명하도록 장려하여 올바른 응답의 가능성을 높입니다. 이 개념의 기원은 2022년 1월의 다음과 같은 제목의 논문으로 거슬러 올라갈 수 있습니다: [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903).

핵심적으로 CoT 기술은 프롬프트에 다음과 유사한 것을 추가하여 구현할 수 있습니다:

![Untitled](/assets/img/About%20Prompt%20Engineering/Untitled%2014.png)

한 단계, 한 단계 밟아가며 논리적이긴 하지만 여전히 맞는 답을 내놓지는 못했습니다.

### **Tree-of-Thought Prompting**

그렇다면,  ToT 스타일의 프롬프트를 어떻게 활용함으로써 CoT의 결과를 개선할 수 있을까요?

[Hulbert(2023)](https://papago.naver.net/apis/site/proxy?url=https%3A%2F%2Fgithub.com%2Fdave1010%2Ftree-of-thought-prompting)는 ToT 프레임워크의 주요 개념을 간단한 프롬프트 기술로 적용하여 LLM이 단일 프롬프트에서 중간 생각을 평가하도록 하는 Tree-of-Thought Prompting을 제안했습니다. 샘플 ToT 프롬프트는 다음과 같습니다.

(영어를 번역한 내용입니다)

```
세 명의 다른 전문가들이 이 질문에 답하고 있다고 상상해 보세요.
모든 전문가들은 한 단계마다 그들의 생각을 적을 것입니다.
그런 다음 그룹과 공유합니다.
그러면 모든 전문가들이 다음 단계 등으로 넘어갑니다.
어떤 전문가가 어느 시점에서든 그들이 틀렸다는 것을 깨닫는다면, 그들은 떠날 것입니다.
문제는...
```

기본 원칙은 LLM이 진행됨에 따라 자체적으로 평가하면서 여러 분기의 추론을 탐구할 수 있는 기회를 제공하는 것입니다. 참고 문헌에 따르면, 이 접근법은 특정 문제에 매우 효과적인 것으로 보입니다.

참고 문헌

- [Large Language Model Guided Tree-of-Thought](https://arxiv.org/abs/2305.08291), 15 May 2023. [Github](https://github.com/jieyilong/tree-of-thought-puzzle-solver).
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601), 17 May 2023. [Github](https://github.com/ysymyth/tree-of-thought-llm) (no code as of 22nd May)
- [Tree of Thoughts](https://github.com/kyegomez/tree-of-thoughts) Github, 21st May 2023

테스트를 해 볼까요

앞서 제시한 프롬프트를 사용하여 같은 질문을 해보았습니다. 

그리고 아래는 chat-gpt3.5의 대답입니다.

![Untitled](/assets/img/About%20Prompt%20Engineering/Untitled%2015.png)

앞서 제안한 프롬프트를 주고 문제를 풀어보도록 했지만 결과적으로 답을 맞추지는 못했습니다. 올바른 답을 얻기 위해서 프롬프트도 수정해보고, 문제도 바꿔봤는데 완벽한 정답에 도달하기는 쉽지 않았습니다. 전부 위와 같은 논리적인척 하는오답만 나열할 뿐이었습니다.  (저의 시행착오가 부족했 걸 수도 있습니다.)  

한참을 시도하다가 되긴 하는걸까 하고 영문으로 프롬프트를 작성 해보았습니다.

![Untitled](/assets/img/About%20Prompt%20Engineering/Untitled%2016.png)

프롬프트를 영어로 하니 정답을 맞춘 것을 볼 수 있었습니다. 대답하는 전문가들의 수준 또한 달라졌습니다. 아무래도 영어로 만들어졌기 때문에 빠르고 정확한 답을 찾는데에는 영어 프롬프트를 구성해야 한다는걸 다시 한번 느낍니다.

### 결론

결과적으로 기존의 CoT 프롬프트에 비해 성능이 향상되었음을 알 수 있었습니다.

ToT 프레임워크는 예제 프롬프트에 표시된 구성 요소보다 더 많은 구성 요소를 포함하는 한계를 포함하고 있습니다.

글에서 흥미를 느끼셨거나 프롬프트에 대한 관심이 생기셨다면 직접 해보거나 [이곳](https://github.com/dave1010/tree-of-thought-prompting)을 방문하셔서 글을 읽어보시는것을 추천드립니다

그리고 혹시 gpt3.5로부터 한국어로 정답을 뽑아낸 분이 계시다면 제보 부탁드립니다.. 

reference

[https://github.com/dave1010/tree-of-thought-prompting](https://github.com/dave1010/tree-of-thought-prompting)

# 프롬프트 엔지니어가 하는 일

# 프롬프트 엔지니어가 되려면

뛰어난 프롬프트 엔지니어의 3가지 조건

1. 사용 하는 AI에 대한 이해
    1. 프롬프트 엔지니어링 대상인 AI에 대한 이해가 없다면 아무리 프롬프트를 잘 써도 원하는 결과를 얻기가 어렵다.
2. 프롬프트 작성 스킬
    1. AI가 가진 성능을 최대한 끌어다 쓸 수 있도록 프롬프트 엔지니어링 스킬을 능숙하게 사용해야 한다.
3. 문제 해결 능력
    1. AI에 대한 이해와 프롬프트 작성 스킬이 뛰어나더라도 원하는 결과가 나오지 않았을 때, 그 문제점과 원인을 분석하고 해결할 수 있어야 한다.

앞으로의 전망?

앞으로 프롬프트 엔지니어링을 잘 활용하는 사람이 살아남을것

1. 경험
2. 사고력
3. 역량

reference

[https://github.com/dave1010/Prompt-Engineering-Guide](https://github.com/dave1010/Prompt-Engineering-Guide)

[https://zapier.com/blog/prompt-engineering](https://zapier.com/blog/prompt-engineering)

[https://www.techtarget.com/searchenterpriseai/definition/prompt-engineering](https://www.techtarget.com/searchenterpriseai/definition/prompt-engineering)

[https://www.codestates.com/blog/content/프롬프트-프롬프트엔지니어링](https://www.codestates.com/blog/content/%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8-%ED%94%84%EB%A1%AC%ED%94%84%ED%8A%B8%EC%97%94%EC%A7%80%EB%8B%88%EC%96%B4%EB%A7%81)

[http://www.itdaily.kr/news/articleView.html?idxno=214302](http://www.itdaily.kr/news/articleView.html?idxno=214302)

[https://seongjin.me/prompt-engineering-in-chatgpt/](https://seongjin.me/prompt-engineering-in-chatgpt/)

[https://moonlang.tistory.com/29](https://moonlang.tistory.com/29) -->