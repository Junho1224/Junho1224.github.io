---
layout: post
title: "What is Prompt Engineering?"
subtitle: "이건어디에들어가는거지"
category: PE
tags: 프롬프트엔지니어 PE
comments: true
---

# About Prompt Engineering : 7. 생각의 나무 프롬프트

**생각의 나무(Tree-of-Thought)** 프롬프트는 생각의 나무 프레임워크에서 아이디어를 차용한 신선한 기술로 잘 확립된 생각의 사슬 프롬프트 개념을 확장하고 향상시켜 ChatGPT와 같은 큰 언어 모델이 우수한 추론 능력을 발휘할 수 있도록 하는 프롬프트입니. 이 Tree-of-Thought Prompting 기술을 통해 Large Language Model은 점진적으로 지식을 축적하면서 오류를 자율적으로 수정할 수 있습니다.

ToT 프롬프트는 이전에는 대답할수 없던 질문에 대답할 수 있도록 ChatGPT 3.5의 추론 능력을 향상시킵니다.

### LLMs에 대한 복잡한 질문

LLM(대규모 언어 모델)은 종종 특정 유형의 복잡한 질문에 정확한 답을 못하는 경우기 있습니다 대표적인 예는 다음과 같습니다.

(참고한 눈문을 번역했습니다.)

```
밥은 거실에 있습니다.
그는 컵을 들고 부엌으로 걸어갑니다.
그는 컵에 공을 넣고 컵을 침실로 옮깁니다.
그는 컵을 뒤집고 정원으로 걸어갑니다.
그는 컵을 정원에 내려놓고 차고로 걸어갑니다.
공은 어디에 있나요?
```

정답은 ‘공은 침실에 있다’ 입니다. 침실에서 공이 든 컵을 뒤집었기 때문이죠!
gpt은 비결정론적 알고리즘이지만, 여러 번 시도하는 동안 받은 답변은 아래와 같습니다.

![제목없음](/assets/img/About%20Prompt%20Engineering/tot/Untitled.png)
*아쉬운 모습을 보여주는 gpt 3.5*

![제목없음](/assets/img/About%20Prompt%20Engineering/tot/Untitled%201.png)
*정답을 맞춘 GPT 4*

프롬프트를 어떻게 구성해야 3.5에서도 답을 맞출 수 있을까요?

### **Chain-of-Thought prompting**

앞서 다뤘던 "생각의 사슬 프롬프트"(CoT)로 널리 알려진 개념이 존재하며, 이는 LLM(Large Language Model)이 생각 과정을 설명하도록 장려하여 올바른 응답의 가능성을 높입니다. 

CoT 프롬프트를 활용하여 질문에 답할 수 있는지 보겠습니다.

![Untitled](/assets/img/About%20Prompt%20Engineering/tot/Untitled%202.png)

한 단계, 한 단계 밟아가며 논리적이긴 하지만 여전히 맞는 답을 내놓지는 못했습니다.

### **Tree-of-Thought Prompting**

그렇다면, ToT 프롬프트를 어떻게 활용함으로써 CoT도 도출하지 못한 결과를 개선할 수 있을까요?

[Hulbert(2023)](https://papago.naver.net/apis/site/proxy?url=https%3A%2F%2Fgithub.com%2Fdave1010%2Ftree-of-thought-prompting)는 ToT 프레임워크의 주요 개념을 간단한 프롬프트 기술로 적용하여 LLM이 단일 프롬프트에서 중간 생각을 평가하도록 하는 Tree-of-Thought Prompting을 제안했습니다. 샘플 ToT 프롬프트는 다음과 같습니다.

(영어를 번역한 내용입니다)

```
세 명의 다른 전문가들이 이 질문에 답하고 있다고 상상해 보세요.
모든 전문가들은 한 단계마다 그들의 생각을 적을 것입니다.
그런 다음 그룹과 공유합니다.
그러면 모든 전문가들이 다음 단계 등으로 넘어갑니다.
어떤 전문가가 어느 시점에서든 그들이 틀렸다는 것을 깨닫는다면, 그들은 떠날 것입니다.
문제는...
```

기본 원칙은 LLM이 진행됨에 따라 자체적으로 평가하면서 여러 분기의 추론을 탐구할 수 있는 기회를 제공하는 것입니다. 참고 문헌에 따르면, 이 접근법은 특정 문제에 매우 효과적인 것으로 보입니다.

테스트를 해 볼까요

앞서 제시한 프롬프트를 사용하여 같은 질문을 해보았습니다. 

그리고 아래는 chat-gpt3.5의 대답입니다.

![Untitled](/assets/img/About%20Prompt%20Engineering/tot/Untitled%203.png)

앞서 제안한 프롬프트를 주고 문제를 풀어보도록 했지만 결과적으로 답을 맞추지는 못했습니다. 올바른 답을 얻기 위해서 프롬프트도 수정해보고, 문제도 바꿔봤는데 완벽한 정답에 도달하기는 쉽지 않았습니다. 전부 위와 같은 논리적인척 하는오답만 나열할 뿐이었습니다.  (저의 시행착오가 부족했 걸 수도 있습니다.)  

한참을 시도하다가 되긴 하는걸까 하고 영문으로 프롬프트를 작성 해보았습니다.

![Untitled](/assets/img/About%20Prompt%20Engineering/tot/Untitled%204.png)

프롬프트를 영어로 하니 정답을 맞춘 것을 볼 수 있었습니다. 대답하는 전문가들의 수준 또한 달라졌습니다. 아무래도 영어로 만들어졌기 때문에 빠르고 정확한 답을 찾는데에는 영어 프롬프트를 구성해야 한다는걸 다시 한번 느낍니다.

### 결론

결과적으로 기존의 CoT 프롬프트에 비해 성능이 향상되었음을 알 수 있었습니다.

ToT 프레임워크는 예제 프롬프트에 표시된 구성 요소보다 더 많은 구성 요소를 포함하는 한계를 포함하고 있습니다.

글에서 흥미를 느끼셨거나 생각의 나무 프롬프트에 대한 관심이 생기셨다면 직접 해보거나 [이곳](https://github.com/dave1010/tree-of-thought-prompting)을 방문하셔서 글을 읽어보시는것을 추천드립니다

그리고 혹시 gpt3.5로부터 한국어로 정답을 뽑아낸 분이 계시다면 제보 부탁드립니다.. 




---


## reference

- [Large Language Model Guided Tree-of-Thought](https://arxiv.org/abs/2305.08291), 15 May 2023. [Github](https://github.com/jieyilong/tree-of-thought-puzzle-solver).
- [Tree of Thoughts: Deliberate Problem Solving with Large Language Models](https://arxiv.org/abs/2305.10601), 17 May 2023. [Github](https://github.com/ysymyth/tree-of-thought-llm) (no code as of 22nd May)
- [Tree of Thoughts](https://github.com/kyegomez/tree-of-thoughts) Github, 21st May 2023
- [https://mpost.io/prompt-engineering-ultimate-guide/](https://mpost.io/prompt-engineering-ultimate-guide/)
- [https://www.promptingguide.ai/](https://www.promptingguide.ai/)